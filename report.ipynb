{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1004eea",
   "metadata": {},
   "source": [
    "# <center>Term project</center>\n",
    "\n",
    "<center>Matti Remes, Lauri Porkka</center>\n",
    "<center>Team name: Team 3</center>\n",
    "<center>19.12.2025</center>\n",
    "\n",
    "\n",
    "## <center>Data exploration</center>\n",
    "\n",
    "The first observation made was that the data has 100 features after dropping the columns \"id\", \"date\", \"partlybad\" and \"class4\". The training samples were skewed toward specific months of the year. For example, samples from the month of February are underrepresented.\n",
    "\n",
    "Due to lack of domain knowledge and limited time, we were not able to come up with ideas for useful interaction features, but they might be beneficial. \n",
    "\n",
    "## <center>Approach</center>\n",
    "\n",
    "To solve the two classification problems \"class2\" and \"class4\", we used two separate models: one for multi-label classification and one for binary classification problem.\n",
    "\n",
    "To find the models that perform the best on the given training data, we use 10-fold cross validation to generate 10 train-test splits and grid search to generate model-parameter combinations. After that the generated models are scored and the best model is selected based on an built-in metric (roc_auc_ovr = ROC-AUC one-versus-rest).\n",
    "\n",
    "The models that were selected for search in both classification problems are:\n",
    "* Random Forest\n",
    "* Logistic Regression (both L1 and L2 penalty)\n",
    "* Support Vector Classifier\n",
    "\n",
    "Preprocessing steps that were applied before fitting data to these models are StandardScaling and PCA (except not for Random Forests). Parameters that were in the search were regularization strength (C) for Support Vector and Logistic Regression classifiers and different tree-based classification parameters for Random Forest (e.g. tree depth, minimum number of samples per leaf etc.)\n",
    "\n",
    "The best multi-label classification model is used to get predictions for class4, and the best binary classification model is used to get $p(class2=event)$.\n",
    "\n",
    "## <center>Conclusion</center>\n",
    "\n",
    "By using two different classifiers, we were able to get decent results on both of the problems. It helped to use grid search to find the best performing model with its parameters.\n",
    "\n",
    "For multi-label classification the best model from the evaluated ones was Random Forest and Logistic Regression with Lasso regularization for binary classification. Using PCA improved training time but using it had a decremental effect on the score.\n",
    "\n",
    "## <center>Grading</center>\n",
    "3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
